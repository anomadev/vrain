## Definición
Top-K es una técnica de muestreo que restringe la selección del siguiente token ([[5.1.5 Common Terminology]]) a los `K` tokens más probables según la distribución generada por el modelo. En lugar de considerar todo el vocabulario (que puede ser de más de 50,000 tokens), el sistema descarta todos los que no estén es el ranking superior de `K`. Esto elimina la "larga cola" de tokens improbables que podrían causar incoherencias.

### Conceptos Clave
- **Ranking Fijo**: A diferencia de `Top-P` ([[5.2.4 Top-P]]), el número de candidatos es constante. Si $K=50$, siempre se elegirán los 50 mejores, independientemente de qué tan alta o baja sea su probabilidad combinada.
- **Long Tail Filtering**: Su función principal es mitigar el riesgo de que el modelo elija un token con probabilidad muy baja (ruido) que arruine la lógica de la secuencia.
- **Balance de Diversidad**: Un $K$ bajo (ej. 1-10) genera respuestas muy conservadoras y repetitivas. Un $K$ alto (ej. 50-100) permite mayor variedad, pero aumenta el riesgo de perder el hilo conductor.
- **Precedencia**: Generalmente se aplica después de la `Temperature` ([[5.2.1 Temperature]]) y puede combinarse con Top-P.

### Escenarios de Aplicación e Identificación
**Donde aplicarlo?**
- **Generación de Código**: Un $K$ bajo (ej. $K=40$) es preferible para asegurar que las palabras clave del lenguaje y las estructuras comunes tengan prioridad absoluta.
- **Sistemas de Recomendación Basados en Texto**: Para asegurar que las sugerencias se mantengan dentro de un dominio semántico coherente y no sugieran conceptos totalmente inconexos.
**Cómo identificarlo?**
- **Respuestas "Encajonadas"**: Si notas que el modelo usa un vocabulario muy limitado o repite las mismas estructuras gramaticales, es probable que el valor de $K$ sea demasiado bajo.
- **Incoherencia Repentina**: Si el modelo introduce palabras que no tienen sentido en el contexto (y la temperatura es moderada), el valor de $K$ podría estar demasiado alto, permitiendo que tokens de la "cola larga" se filtren en la respuesta.

## Notas Personales
Desde la arquitectura de software, Top-K es nuestro "**Limitador de Varianza**". En sistemas donde la consistencia es clave pero no queremos la rigidez total de una temperatura cero, ajustar $K$ nos permite podar las opciones más absurdas del modelo. Un error común es pensar que $K$ depende del tamaño del input; en realidad, depende de la **complejidad semántica** que desees permitir en el output.