## Definición
Las `Stop Sequences` son cadenas de texto (`strings`)configurables que, al ser generadas por el modelo, fuerzan la detención inmediata de la respuesta. El modelo monitorea su propia salida `token` por `token` ([[5.1.5 Common Terminology]]) y, si la la secuencia especifica aparece, el API cortara la conexión y devuelve el resultado generado hasta ese punto (excluyendo la secuencia de parada misma). Es una herramienta fundamental para garantizar la integridad estructural de las respuestas.

## Conceptos Claves
- **Determinismo de estructura**: Permiten que el modelo no se "desborde" fuera del formato esperado. (ej. detenerse al cerrar una etiqueta XML o un bloque de código).
- **Token Matching**: La secuencia de parada debe ser algo que el modelo generaría naturalmente como fin de una idea (ej. `\n`, `User:`, `</html>`).
- **Exclusión de la Secuencia**: Por lo general, la cadena que dispara la parada no se incluye en el texto final devuelto por el API, lo cual es ideal para limpiar el output antes de procesarlo.
- **Múltiples Centinelas**: La mayoría de los proveedores de LLM permiten definir hasta 4 secuencias de parada diferentes por petición.

## Escenarios de Aplicación e Identificación
**Donde aplicarlo?**
- **Chatbots Multi-agents**: Si estás simulando un diálogo, puedes usar `User:` como stop sequence para evitar que el modelo empiece a escribir las respuestas del usuario por si mismo.
- **Generación de Código**: En un entorno de autocompletado, podrías usar `\nclass` o `\nfunction` para que el modelo solo genere el cuerpo de la función actual y no intente escribir todo el archivo.
- Extracción de Datos: Si pides un valor específico dentro de un formato, como `Clave: [VALOR]`, puedes poner `\n` como stop sequence para asegurar que el modelo no agregue explicaciones después del valor.
**Cómo identificarlo?**
- **Rambling (Divagación)**: Si el modelo responde la pregunta pero luego continúa escribiendo contenido irrelevante o simulando otros roles, te faltan `Stop Sequences`.
- **Finish Reason** `stop`: Cuando el API devuelve este estado, sabes que el modelo se detuvo porque encontró uno de tus centinelas, no porque se quedó sin tokens o terminó naturalmente.

## Notas Personales
Un truco de arquitectura: si estás usando el modelo para generar `JSON` y no tienes un modo `JSON` nativo, usa `}` como stop sequence. Esto evita que el modelo añada texto como "*Espero que este JSON te sirva*" después del objeto, lo cual rompería tu `json_decode()`.