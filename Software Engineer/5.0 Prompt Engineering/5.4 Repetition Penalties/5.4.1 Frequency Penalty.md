## Definición
La `Frequency Penalty` es un parámetro que penaliza los `tokens` ([[5.1.5 Common Terminology]]) basándose en cuántas veces han aparecido ya en el texto generado. A diferencia de la [[5.4.2 Presence Penalty]] (que es binaria), la `Frequency Penalty` es acumulativa: mientras más veces se repite un `token` específico, mayor es la penalización que recibe, reduciendo drásticamente la probabilidad de que el modelo lo elija nuevamente.
Matemáticamente, se aplica una resta al $logic$ del token $j$ de la siguiente forma:
$$logits_j = logits_j - (count \times penalty)$$
Donde $count$ es el número de veces que el token ha aparecido en la respuesta hasta ese momento.

## Conceptos Clave
- **Penalización Acumulativa**: El "castigo" crece linealmente con cada aparición. Esto combate directamente los bucles repetitivos de palabras o frases comunes.
- **Diversidad de Vocabulario**: Al reducir la probabilidad de palabras usadas frecuentemente (como conectores o sustantivos específicos), obliga al modelo a buscar sinónimos o variar la estructura.
- **Rango Típico**: Generalmente oscila entre 0.0 y 2.0. Valores positivos disminuyen la repetición; valores negativos (raramente usados) la incentivan.
- **Costo Computacional**: Se calcula en tiempo real durante la inferencia (token por token), lo que añade un ligero procesamiento al motor de muestreo.

## Escenarios de Aplicación e Identificación
**¿Dónde aplicarlo?**
- **Escritura Creativa o Artículos**: Para evitar que el modelo use excesivamente la misma palabra clave o muletillas, haciendo que el texto se sienta más "humano" y variado.
- **Resúmenes de Larga Extensión**: En textos largos, los modelos tienden a "enamorarse" de ciertas frases. Un toque de `Frequency Penalty` mantiene la frescura del contenido. 
- **Generación de Descripciones de Productos**: Cuando tiene que generar 100 descripciones similares, este parámetro ayuda a que no todas suenen exactamente igual.
**¿Cómo identificarlo?**
- **"Echoing" o Bucles**: Si el modelo entra en un loop infinito repitiendo la misma frase (ej: "Además, es importante notar que... Además, es importante notar que..."), la `Frequency Penalty` es demasiado baja.
- Incoherencia por Sinónimos Forzados: Si notas que el modelo empieza a usar palabras muy extrañas o rebuscadas para conceptos simples, es posible que la `Frequency Penalty` esté demasiado alta, prohibiéndole usar palabras necesarias por el simple hecho de haberlas usado antes.

## Notas Personales
En la ingeniería de prompts, a menudo olvidamos que el lenguaje natural tiene una estructura redundante por diseño. Mi recomendación general es empezar con valores bajos (0.1 a 0.5). Si subes demasiado este parámetro en tareas técnicas o de código, el modelo "romperá" la sintaxis porque se sentirá "obligado" a no repetir una variable o una palabra clave (como `if` o `return`), lo cual es desastroso. Úsalo con un bisturí, no como un mazo.
