## Definición
El `Zero-Shot Prompting` es una técnica donde se le pide a un LLM ([[5.1.5 Common Terminology]]) que realice una tarea sin proporcionarle ningún ejemplo previo (shots) de cómo debe ser el resultado. El modelo se basa exclusivamente en su entrenamiento masivo y en la semántica de la instrucción para inferir la lógica de la respuesta. Es, esencialmente, confiar en el "sentido común" estadístico del modelo.

## Conceptos Clave
- **Semantic Alignment**: La efectividad depende de que los términos usados en la instrucción coincidan con los conceptos que el modelo domina (*ej. Sentiment Analysis* es un concepto estándar).
- **Cold Start**: No requiere una fase de "calentamiento" contextual o ejemplos de entrada/salida.
- **Instruction Tuning**: Esta técnica funciona gracias a que los modelos modernos han sido entrenados específicamente para seguir instrucciones (RLHF)
- **Token Efficiency**: Al no incluir ejemplos, se reduce el costo operativo y se maximiza el espacio disponible en la Ventana de Contexto para la respuesta.

## Escenarios de Aplicación e Identificación
**¿Dónde aplicarlo?**
- **Tareas Estándar de NLP**: Clasificación de texto, traducción de idiomas comunes o análisis de sentimiento simple.
- **Prototipado Rápido**: Cuando necesitas validar si un modelo es capaz de entender un requerimiento de negocio sin invertir tiempo en crear un dataset de ejemplos.
- **Generación de Contenido General**: Redacción de correos, resúmenes o explicaciones de conceptos técnicos conocidos
**¿Cómo identificarlo?**
- **Estructura del Prompt**: El prompt solo contiene la instrucción y los datos a procesar (*ej. "Clasifica este texto ..."*) No hay bloques del tipo "*Entrada X -> Salida: Y*".
- **Falla por Falta de Contexto**: Si el modelo responde correctamente a la gramática pero falla en el formato específico que tu software requiere, has llegado al límite del `Zero-Shot` y necesitas evolucionar a `Few-Shot` ([[5.6.2 One-Shot & Few-Shot Prompting]]).

## Notas Personales 
Desde el diseño de sistemas, el `Zero Shot` debe ser siempre tu punto de partida (Baseline). Si una tarea se resuelve con `Zero-Shot`, no añadas complejidad. Sin embargo, ten cuidado con la ambigüedad. Un error común es pensar que el modelo "sabe lo que quiero". Si el modelo falla, antes de saltar a `Few-Shots` (ejemplos), intenta mejorar la especificidad de la instrucción (Role Prompting).